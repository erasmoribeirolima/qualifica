{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega o dataset\n",
    "dados = pd.read_csv('/home/erasmor/Downloads/2017/todos_apenas_baixa_representatividade.csv',sep=\",\",encoding = 'utf-8',  header=0,na_values='.',dtype={'Label':'category'})\n",
    "#remove valores infinitos\n",
    "dados.replace(-np.Inf, np.nan)\n",
    "#substitui valores NaN\n",
    "dados.fillna(dados.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica quantas instâncias (linhas) e quantos atributos (colunas) a base de dados contém\n",
    "print(\"numero de linhas e colunas: \",dados.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar distribições por classes contidas no csv - informar nome da classe alvo\n",
    "print(dados.groupby('Label').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(dados.columns)\n",
    "# colunas que nao serao normalizadas\n",
    "cols.remove('Label')\n",
    "# Copiando os dados e aplicando a normalizacao por reescala nas colunas do DataFrame que contem\n",
    "# valores continuos. Por padrao, o metodo minmax_scale reescala com min=0 e max=1.\n",
    "dados = dados[~dados.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "dados[cols] = dados[cols].apply(minmax_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define as colunas de atributos e a coluna da classe (de 0 a 78 são atributos e após a 78 é a classe)\n",
    "X_raw = dados.iloc[:, :-1].values # atributos\n",
    "y_raw = dados.iloc[:, 78].values # classe de ataques\n",
    "X_raw = np.nan_to_num(X_raw.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformar a variável y com valores categóricos (classses de ataques) em valores numéricos:\n",
    "labelencoder_y = LabelEncoder()\n",
    "y_raw = labelencoder_y.fit_transform(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando um PCA. O parametro n_components indica a quantidade de dimensoes que a base\n",
    "# original sera reduzida.\n",
    "pca = PCA(n_components=10, whiten=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o pca na base de dados. O atributo 'values' retorna um numpy.array\n",
    "# de duas dimensões (matriz) contendo apenas os valores numericos do DataFrame.\n",
    "X_raw = pca.fit_transform(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling_knn(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    #define nome de arquivos para salvar\n",
    "    indica_pool=str(idx_dobra)\n",
    "           \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "   \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    arquivo_accuracy_knn = open(\"random_accuracy_performance_knn_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_knn = (\"random_accuracy_history_knn_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_knn = (\"random_F1_Score_history_knn_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_knn = (\"random_tempo_history_knn_dobra_\"+indica_pool+\".csv\")\n",
    "    \n",
    "    #Registro da pontuação na porção de teste com o treinamento inicial\n",
    "    performance_history_knn=[]\n",
    "    f1_score_history_knn=[]\n",
    "    tempo_history_knn=[]\n",
    "    learner_knn.fit(X_train, y_train)\n",
    "    predictions = learner_knn.predict(X_teste)\n",
    "    random_sample_score_knn = accuracy_score(y_teste, predictions)\n",
    "    performance_history_knn.append(random_sample_score_knn)\n",
    "    f1score_knn = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_knn.append(f1score_knn)\n",
    "    \n",
    "    #Aprendizado Ativo\n",
    "  \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_knn = time.time()\n",
    "        n_labeled_examples_pool = X_pool.shape[0]\n",
    "        training_indices_pool = np.random.randint(low=0, high=n_labeled_examples_pool, size=BATCH_SIZE)\n",
    "        X_temp= X_pool[training_indices_pool]\n",
    "        y_temp= y_pool[training_indices_pool]\n",
    "        X_train=np.append(X_train,X_temp, axis=0)\n",
    "        y_train=np.append(y_train,y_temp, axis=0)\n",
    "        learner_knn.fit(X_train, y_train)\n",
    "        predictions = learner_knn.predict(X_teste)\n",
    "        performance_history_knn.append(accuracy_score(y_teste, predictions))\n",
    "        \n",
    "        #apaga registros consultados\n",
    "        X_pool = np.delete(X_pool, training_indices_pool, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_pool, axis=0)\n",
    "        \n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_knn = time.time()\n",
    "        time_elapsed_knn = (t2_knn-t1_knn)\n",
    "        hours_knn, rem_knn = divmod(time_elapsed_knn, 3600)\n",
    "        minutes_knn, seconds_knn = divmod(rem_knn, 60)\n",
    "        tempo_history_knn.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_knn),int(minutes_knn),int(seconds_knn)))\n",
    "        #grava dados\n",
    "        clear_output(wait=True)\n",
    "        print ('Accuracy_knn after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "        arquivo_accuracy_knn.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "        #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_knn.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "        #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_test, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_knn.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        #arquivo_accuracy_knn.write('F1 Score after query no. %d: %f \\n' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        f1score_knn= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_knn.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_knn))\n",
    "        f1_score_history_knn.append(f1score_knn)\n",
    "        #print (\"========================================\")\n",
    "        arquivo_accuracy_knn.write('======================================== \\n')\n",
    "        \n",
    "        \n",
    "   \n",
    "    arquivo_accuracy_knn.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_knn.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_knn, performance_history_knn,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_knn, f1_score_history_knn)\n",
    "    np.savetxt(arquivo_tempo_history_knn,tempo_history_knn,fmt=\"%s\")\n",
    "    arquivo_accuracy_knn.close()\n",
    "    \n",
    "def random_sampling_rf(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    #define nome de arquivos para salvar\n",
    "    indica_pool=str(idx_dobra)\n",
    "           \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "   \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_rf = RandomForestClassifier(random_state=42)\n",
    "    arquivo_accuracy_rf = open(\"random_accuracy_performance_rf_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_rf = (\"random_accuracy_history_rf_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_rf = (\"random_F1_Score_history_rf_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_rf = (\"random_tempo_history_rf_dobra_\"+indica_pool+\".csv\")\n",
    "    \n",
    "    #Registro da pontuação na porção de teste com o treinamento inicial\n",
    "    performance_history_rf=[]\n",
    "    f1_score_history_rf=[]\n",
    "    tempo_history_rf=[]\n",
    "    learner_rf.fit(X_train, y_train)\n",
    "    predictions = learner_rf.predict(X_teste)\n",
    "    random_sample_score_rf = accuracy_score(y_teste, predictions)\n",
    "    performance_history_rf.append(random_sample_score_rf)\n",
    "    f1score_rf = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_rf.append(f1score_rf)\n",
    "    \n",
    "    #Aprendizado Ativo\n",
    "  \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_rf = time.time()\n",
    "        n_labeled_examples_pool = X_pool.shape[0]\n",
    "        training_indices_pool = np.random.randint(low=0, high=n_labeled_examples_pool, size=BATCH_SIZE)\n",
    "        X_temp= X_pool[training_indices_pool]\n",
    "        y_temp= y_pool[training_indices_pool]\n",
    "        X_train=np.append(X_train,X_temp, axis=0)\n",
    "        y_train=np.append(y_train,y_temp, axis=0)\n",
    "        learner_rf.fit(X_train, y_train)\n",
    "        predictions = learner_rf.predict(X_teste)\n",
    "        performance_history_rf.append(accuracy_score(y_teste, predictions))\n",
    "        \n",
    "        #apaga registros consultados\n",
    "        X_pool = np.delete(X_pool, training_indices_pool, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_pool, axis=0)\n",
    "        \n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_rf = time.time()\n",
    "        time_elapsed_rf = (t2_rf-t1_rf)\n",
    "        hours_rf, rem_rf = divmod(time_elapsed_rf, 3600)\n",
    "        minutes_rf, seconds_rf = divmod(rem_rf, 60)\n",
    "        tempo_history_rf.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_rf),int(minutes_rf),int(seconds_rf)))\n",
    "        #grava dados\n",
    "        clear_output(wait=True)\n",
    "        print ('Accuracy_rf after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "        arquivo_accuracy_rf.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "        #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_rf.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "        #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_test, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_rf.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        #arquivo_accuracy_rf.write('F1 Score after query no. %d: %f \\n' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        f1score_rf= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_rf.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_rf))\n",
    "        f1_score_history_rf.append(f1score_rf)\n",
    "        #print (\"========================================\")\n",
    "        arquivo_accuracy_rf.write('======================================== \\n')\n",
    "        \n",
    "        \n",
    "   \n",
    "    arquivo_accuracy_rf.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_rf.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_rf, performance_history_rf,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_rf, f1_score_history_rf)\n",
    "    np.savetxt(arquivo_tempo_history_rf,tempo_history_rf,fmt=\"%s\")\n",
    "    arquivo_accuracy_rf.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "def random_sampling_tree(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    #define nome de arquivos para salvar\n",
    "    indica_pool=str(idx_dobra)\n",
    "           \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "   \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_tree = DecisionTreeClassifier(max_depth=5,min_samples_split=2,min_samples_leaf=2)\n",
    "    arquivo_accuracy_tree = open(\"random_accuracy_performance_tree_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_tree = (\"random_accuracy_history_tree_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_tree = (\"random_F1_Score_history_tree_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_tree = (\"random_tempo_history_tree_dobra_\"+indica_pool+\".csv\")\n",
    "    \n",
    "    #Registro da pontuação na porção de teste com o treinamento inicial\n",
    "    performance_history_tree=[]\n",
    "    f1_score_history_tree=[]\n",
    "    tempo_history_tree=[]\n",
    "    learner_tree.fit(X_train, y_train)\n",
    "    predictions = learner_tree.predict(X_teste)\n",
    "    random_sample_score_tree = accuracy_score(y_teste, predictions)\n",
    "    performance_history_tree.append(random_sample_score_tree)\n",
    "    f1score_tree = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_tree.append(f1score_tree)\n",
    "    \n",
    "    #Aprendizado Ativo\n",
    "  \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_tree = time.time()\n",
    "        n_labeled_examples_pool = X_pool.shape[0]\n",
    "        training_indices_pool = np.random.randint(low=0, high=n_labeled_examples_pool, size=BATCH_SIZE)\n",
    "        X_temp= X_pool[training_indices_pool]\n",
    "        y_temp= y_pool[training_indices_pool]\n",
    "        X_train=np.append(X_train,X_temp, axis=0)\n",
    "        y_train=np.append(y_train,y_temp, axis=0)\n",
    "        learner_tree.fit(X_train, y_train)\n",
    "        predictions = learner_tree.predict(X_teste)\n",
    "        performance_history_tree.append(accuracy_score(y_teste, predictions))\n",
    "        \n",
    "        #apaga registros consultados\n",
    "        X_pool = np.delete(X_pool, training_indices_pool, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_pool, axis=0)\n",
    "        \n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_tree = time.time()\n",
    "        time_elapsed_tree = (t2_tree-t1_tree)\n",
    "        hours_tree, rem_tree = divmod(time_elapsed_tree, 3600)\n",
    "        minutes_tree, seconds_tree = divmod(rem_tree, 60)\n",
    "        tempo_history_tree.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_tree),int(minutes_tree),int(seconds_tree)))\n",
    "        #grava dados\n",
    "        clear_output(wait=True)\n",
    "        print ('Accuracy_tree after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "        arquivo_accuracy_tree.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "        #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_tree.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "        #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_test, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_tree.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        #arquivo_accuracy_tree.write('F1 Score after query no. %d: %f \\n' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        f1score_tree= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_tree.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_tree))\n",
    "        f1_score_history_tree.append(f1score_tree)\n",
    "        #print (\"========================================\")\n",
    "        arquivo_accuracy_tree.write('======================================== \\n')\n",
    "        \n",
    "        \n",
    "   \n",
    "    arquivo_accuracy_tree.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_tree.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_tree, performance_history_tree,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_tree, f1_score_history_tree)\n",
    "    np.savetxt(arquivo_tempo_history_tree,tempo_history_tree,fmt=\"%s\")\n",
    "    arquivo_accuracy_tree.close()\n",
    "    \n",
    "\n",
    "def random_sampling_mlp(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    #define nome de arquivos para salvar\n",
    "    indica_pool=str(idx_dobra)\n",
    "           \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "   \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_mlp = MLPClassifier(max_iter = 2000)\n",
    "    arquivo_accuracy_mlp = open(\"random_accuracy_performance_mlp_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_mlp = (\"random_accuracy_history_mlp_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_mlp = (\"random_F1_Score_history_mlp_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_mlp = (\"random_tempo_history_mlp_dobra_\"+indica_pool+\".csv\")\n",
    "    \n",
    "    #Registro da pontuação na porção de teste com o treinamento inicial\n",
    "    performance_history_mlp=[]\n",
    "    f1_score_history_mlp=[]\n",
    "    tempo_history_mlp=[]\n",
    "    learner_mlp.fit(X_train, y_train)\n",
    "    predictions = learner_mlp.predict(X_teste)\n",
    "    random_sample_score_mlp = accuracy_score(y_teste, predictions)\n",
    "    performance_history_mlp.append(random_sample_score_mlp)\n",
    "    f1score_mlp = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_mlp.append(f1score_mlp)\n",
    "    \n",
    "    #Aprendizado Ativo\n",
    "  \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_mlp = time.time()\n",
    "        n_labeled_examples_pool = X_pool.shape[0]\n",
    "        training_indices_pool = np.random.randint(low=0, high=n_labeled_examples_pool, size=BATCH_SIZE)\n",
    "        X_temp= X_pool[training_indices_pool]\n",
    "        y_temp= y_pool[training_indices_pool]\n",
    "        X_train=np.append(X_train,X_temp, axis=0)\n",
    "        y_train=np.append(y_train,y_temp, axis=0)\n",
    "        learner_mlp.fit(X_train, y_train)\n",
    "        predictions = learner_mlp.predict(X_teste)\n",
    "        performance_history_mlp.append(accuracy_score(y_teste, predictions))\n",
    "        \n",
    "        #apaga registros consultados\n",
    "        X_pool = np.delete(X_pool, training_indices_pool, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_pool, axis=0)\n",
    "        \n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_mlp = time.time()\n",
    "        time_elapsed_mlp = (t2_mlp-t1_mlp)\n",
    "        hours_mlp, rem_mlp = divmod(time_elapsed_mlp, 3600)\n",
    "        minutes_mlp, seconds_mlp = divmod(rem_mlp, 60)\n",
    "        tempo_history_mlp.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_mlp),int(minutes_mlp),int(seconds_mlp)))\n",
    "        #grava dados\n",
    "        clear_output(wait=True)\n",
    "        print ('Accuracy_mlp after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "        arquivo_accuracy_mlp.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "        #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_mlp.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "        #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_test, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_mlp.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        #arquivo_accuracy_mlp.write('F1 Score after query no. %d: %f \\n' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        f1score_mlp= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_mlp.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_mlp))\n",
    "        f1_score_history_mlp.append(f1score_mlp)\n",
    "        #print (\"========================================\")\n",
    "        arquivo_accuracy_mlp.write('======================================== \\n')\n",
    "        \n",
    "        \n",
    "   \n",
    "    arquivo_accuracy_mlp.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_mlp.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_mlp, performance_history_mlp,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_mlp, f1_score_history_mlp)\n",
    "    np.savetxt(arquivo_tempo_history_mlp,tempo_history_mlp,fmt=\"%s\")\n",
    "    arquivo_accuracy_mlp.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "def random_sampling_xgb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    #define nome de arquivos para salvar\n",
    "    indica_pool=str(idx_dobra)\n",
    "           \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "   \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_xgb = GradientBoostingClassifier(n_estimators=7, learning_rate=1.0,max_depth=1, random_state=42)\n",
    "    arquivo_accuracy_xgb = open(\"random_accuracy_performance_xgb_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_xgb = (\"random_accuracy_history_xgb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_xgb = (\"random_F1_Score_history_xgb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_xgb = (\"random_tempo_history_xgb_dobra_\"+indica_pool+\".csv\")\n",
    "    \n",
    "    #Registro da pontuação na porção de teste com o treinamento inicial\n",
    "    performance_history_xgb=[]\n",
    "    f1_score_history_xgb=[]\n",
    "    tempo_history_xgb=[]\n",
    "    learner_xgb.fit(X_train, y_train)\n",
    "    predictions = learner_xgb.predict(X_teste)\n",
    "    random_sample_score_xgb = accuracy_score(y_teste, predictions)\n",
    "    performance_history_xgb.append(random_sample_score_xgb)\n",
    "    f1score_xgb = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_xgb.append(f1score_xgb)\n",
    "    \n",
    "    #Aprendizado Ativo\n",
    "  \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_xgb = time.time()\n",
    "        n_labeled_examples_pool = X_pool.shape[0]\n",
    "        training_indices_pool = np.random.randint(low=0, high=n_labeled_examples_pool, size=BATCH_SIZE)\n",
    "        X_temp= X_pool[training_indices_pool]\n",
    "        y_temp= y_pool[training_indices_pool]\n",
    "        X_train=np.append(X_train,X_temp, axis=0)\n",
    "        y_train=np.append(y_train,y_temp, axis=0)\n",
    "        learner_xgb.fit(X_train, y_train)\n",
    "        predictions = learner_xgb.predict(X_teste)\n",
    "        performance_history_xgb.append(accuracy_score(y_teste, predictions))\n",
    "        \n",
    "        #apaga registros consultados\n",
    "        X_pool = np.delete(X_pool, training_indices_pool, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_pool, axis=0)\n",
    "        \n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_xgb = time.time()\n",
    "        time_elapsed_xgb = (t2_xgb-t1_xgb)\n",
    "        hours_xgb, rem_xgb = divmod(time_elapsed_xgb, 3600)\n",
    "        minutes_xgb, seconds_xgb = divmod(rem_xgb, 60)\n",
    "        tempo_history_xgb.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_xgb),int(minutes_xgb),int(seconds_xgb)))\n",
    "        #grava dados\n",
    "        clear_output(wait=True)\n",
    "        print ('Accuracy_xgb after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "        arquivo_accuracy_xgb.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "        #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_xgb.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "        #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_test, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_xgb.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        #arquivo_accuracy_xgb.write('F1 Score after query no. %d: %f \\n' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        f1score_xgb= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_xgb.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_xgb))\n",
    "        f1_score_history_xgb.append(f1score_xgb)\n",
    "        #print (\"========================================\")\n",
    "        arquivo_accuracy_xgb.write('======================================== \\n')\n",
    "        \n",
    "        \n",
    "   \n",
    "    arquivo_accuracy_xgb.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_xgb.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_xgb, performance_history_xgb,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_xgb, f1_score_history_xgb)\n",
    "    np.savetxt(arquivo_tempo_history_xgb,tempo_history_xgb,fmt=\"%s\")\n",
    "    arquivo_accuracy_xgb.close()\n",
    "    \n",
    "\n",
    "def random_sampling_svm(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    #define nome de arquivos para salvar\n",
    "    indica_pool=str(idx_dobra)\n",
    "           \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "   \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_svm = svm.SVC(kernel='linear',probability=True)\n",
    "    arquivo_accuracy_svm = open(\"random_accuracy_performance_svm_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_svm = (\"random_accuracy_history_svm_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_svm = (\"random_F1_Score_history_svm_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_svm = (\"random_tempo_history_svm_dobra_\"+indica_pool+\".csv\")\n",
    "    \n",
    "    #Registro da pontuação na porção de teste com o treinamento inicial\n",
    "    performance_history_svm=[]\n",
    "    f1_score_history_svm=[]\n",
    "    tempo_history_svm=[]\n",
    "    learner_svm.fit(X_train, y_train)\n",
    "    predictions = learner_svm.predict(X_teste)\n",
    "    random_sample_score_svm = accuracy_score(y_teste, predictions)\n",
    "    performance_history_svm.append(random_sample_score_svm)\n",
    "    f1score_svm = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_svm.append(f1score_svm)\n",
    "    \n",
    "    #Aprendizado Ativo\n",
    "  \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_svm = time.time()\n",
    "        n_labeled_examples_pool = X_pool.shape[0]\n",
    "        training_indices_pool = np.random.randint(low=0, high=n_labeled_examples_pool, size=BATCH_SIZE)\n",
    "        X_temp= X_pool[training_indices_pool]\n",
    "        y_temp= y_pool[training_indices_pool]\n",
    "        X_train=np.append(X_train,X_temp, axis=0)\n",
    "        y_train=np.append(y_train,y_temp, axis=0)\n",
    "        learner_svm.fit(X_train, y_train)\n",
    "        predictions = learner_svm.predict(X_teste)\n",
    "        performance_history_svm.append(accuracy_score(y_teste, predictions))\n",
    "        \n",
    "        #apaga registros consultados\n",
    "        X_pool = np.delete(X_pool, training_indices_pool, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_pool, axis=0)\n",
    "        \n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_svm = time.time()\n",
    "        time_elapsed_svm = (t2_svm-t1_svm)\n",
    "        hours_svm, rem_svm = divmod(time_elapsed_svm, 3600)\n",
    "        minutes_svm, seconds_svm = divmod(rem_svm, 60)\n",
    "        tempo_history_svm.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_svm),int(minutes_svm),int(seconds_svm)))\n",
    "        #grava dados\n",
    "        clear_output(wait=True)\n",
    "        print ('Accuracy_svm after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "        arquivo_accuracy_svm.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "        #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_svm.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "        #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_test, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_svm.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        #arquivo_accuracy_svm.write('F1 Score after query no. %d: %f \\n' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        f1score_svm= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_svm.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_svm))\n",
    "        f1_score_history_svm.append(f1score_svm)\n",
    "        #print (\"========================================\")\n",
    "        arquivo_accuracy_svm.write('======================================== \\n')\n",
    "        \n",
    "        \n",
    "   \n",
    "    arquivo_accuracy_svm.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_svm.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_svm, performance_history_svm,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_svm, f1_score_history_svm)\n",
    "    np.savetxt(arquivo_tempo_history_svm,tempo_history_svm,fmt=\"%s\")\n",
    "    arquivo_accuracy_svm.close()\n",
    "    \n",
    "\n",
    "def random_sampling_nb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    #define nome de arquivos para salvar\n",
    "    indica_pool=str(idx_dobra)\n",
    "           \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "   \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_nb = GaussianNB()\n",
    "    arquivo_accuracy_nb = open(\"random_accuracy_performance_nb_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_nb = (\"random_accuracy_history_nb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_nb = (\"random_F1_Score_history_nb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_nb = (\"random_tempo_history_nb_dobra_\"+indica_pool+\".csv\")\n",
    "    \n",
    "    #Registro da pontuação na porção de teste com o treinamento inicial\n",
    "    performance_history_nb=[]\n",
    "    f1_score_history_nb=[]\n",
    "    tempo_history_nb=[]\n",
    "    learner_nb.fit(X_train, y_train)\n",
    "    predictions = learner_nb.predict(X_teste)\n",
    "    random_sample_score_nb = accuracy_score(y_teste, predictions)\n",
    "    performance_history_nb.append(random_sample_score_nb)\n",
    "    f1score_nb = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_nb.append(f1score_nb)\n",
    "    \n",
    "    #Aprendizado Ativo\n",
    "  \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_nb = time.time()\n",
    "        n_labeled_examples_pool = X_pool.shape[0]\n",
    "        training_indices_pool = np.random.randint(low=0, high=n_labeled_examples_pool, size=BATCH_SIZE)\n",
    "        X_temp= X_pool[training_indices_pool]\n",
    "        y_temp= y_pool[training_indices_pool]\n",
    "        X_train=np.append(X_train,X_temp, axis=0)\n",
    "        y_train=np.append(y_train,y_temp, axis=0)\n",
    "        learner_nb.fit(X_train, y_train)\n",
    "        predictions = learner_nb.predict(X_teste)\n",
    "        performance_history_nb.append(accuracy_score(y_teste, predictions))\n",
    "        \n",
    "        #apaga registros consultados\n",
    "        X_pool = np.delete(X_pool, training_indices_pool, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_pool, axis=0)\n",
    "        \n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_nb = time.time()\n",
    "        time_elapsed_nb = (t2_nb-t1_nb)\n",
    "        hours_nb, rem_nb = divmod(time_elapsed_nb, 3600)\n",
    "        minutes_nb, seconds_nb = divmod(rem_nb, 60)\n",
    "        tempo_history_nb.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_nb),int(minutes_nb),int(seconds_nb)))\n",
    "        #grava dados\n",
    "        clear_output(wait=True)\n",
    "        print ('Accuracy_nb after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "        arquivo_accuracy_nb.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "        #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_nb.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "        #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_test, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_nb.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        #arquivo_accuracy_nb.write('F1 Score after query no. %d: %f \\n' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        f1score_nb= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_nb.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_nb))\n",
    "        f1_score_history_nb.append(f1score_nb)\n",
    "        #print (\"========================================\")\n",
    "        arquivo_accuracy_nb.write('======================================== \\n')\n",
    "        \n",
    "        \n",
    "   \n",
    "    arquivo_accuracy_nb.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_nb.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_nb, performance_history_nb,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_nb, f1_score_history_nb)\n",
    "    np.savetxt(arquivo_tempo_history_nb,tempo_history_nb,fmt=\"%s\")\n",
    "    arquivo_accuracy_nb.close()\n",
    "    \n",
    "def random_sampling_adb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn import svm\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    #define nome de arquivos para salvar\n",
    "    indica_pool=str(idx_dobra)\n",
    "           \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "   \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_adb = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "    arquivo_accuracy_adb = open(\"random_accuracy_performance_adb_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_adb = (\"random_accuracy_history_adb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_adb = (\"random_F1_Score_history_adb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_adb = (\"random_tempo_history_adb_dobra_\"+indica_pool+\".csv\")\n",
    "    \n",
    "    #Registro da pontuação na porção de teste com o treinamento inicial\n",
    "    performance_history_adb=[]\n",
    "    f1_score_history_adb=[]\n",
    "    tempo_history_adb=[]\n",
    "    learner_adb.fit(X_train, y_train)\n",
    "    predictions = learner_adb.predict(X_teste)\n",
    "    random_sample_score_adb = accuracy_score(y_teste, predictions)\n",
    "    performance_history_adb.append(random_sample_score_adb)\n",
    "    f1score_adb = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_adb.append(f1score_adb)\n",
    "    \n",
    "    #Aprendizado Ativo\n",
    "  \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_adb = time.time()\n",
    "        n_labeled_examples_pool = X_pool.shape[0]\n",
    "        training_indices_pool = np.random.randint(low=0, high=n_labeled_examples_pool, size=BATCH_SIZE)\n",
    "        X_temp= X_pool[training_indices_pool]\n",
    "        y_temp= y_pool[training_indices_pool]\n",
    "        X_train=np.append(X_train,X_temp, axis=0)\n",
    "        y_train=np.append(y_train,y_temp, axis=0)\n",
    "        learner_adb.fit(X_train, y_train)\n",
    "        predictions = learner_adb.predict(X_teste)\n",
    "        performance_history_adb.append(accuracy_score(y_teste, predictions))\n",
    "        \n",
    "        #apaga registros consultados\n",
    "        X_pool = np.delete(X_pool, training_indices_pool, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_pool, axis=0)\n",
    "        \n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_adb = time.time()\n",
    "        time_elapsed_adb = (t2_adb-t1_adb)\n",
    "        hours_adb, rem_adb = divmod(time_elapsed_adb, 3600)\n",
    "        minutes_adb, seconds_adb = divmod(rem_adb, 60)\n",
    "        tempo_history_adb.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_adb),int(minutes_adb),int(seconds_adb)))\n",
    "        #grava dados\n",
    "        clear_output(wait=True)\n",
    "        print ('Accuracy_adb after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "        arquivo_accuracy_adb.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "        #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_adb.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "        #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_test, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_adb.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        #arquivo_accuracy_adb.write('F1 Score after query no. %d: %f \\n' % (index+1, f1_score(y_test, predictions,average='macro',zero_division=1)))\n",
    "        f1score_adb= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "        arquivo_accuracy_adb.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_adb))\n",
    "        f1_score_history_adb.append(f1score_adb)\n",
    "        #print (\"========================================\")\n",
    "        arquivo_accuracy_adb.write('======================================== \\n')\n",
    "        \n",
    "        \n",
    "   \n",
    "    arquivo_accuracy_adb.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_adb.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_adb, performance_history_adb,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_adb, f1_score_history_adb)\n",
    "    np.savetxt(arquivo_tempo_history_adb,tempo_history_adb,fmt=\"%s\")\n",
    "    arquivo_accuracy_adb.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "import time\n",
    "import sys\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit, train_test_split\n",
    "from modAL.uncertainty import classifier_uncertainty\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "from timeit import Timer\n",
    "import time\n",
    "import functools\n",
    "# importing the multiprocessing module\n",
    "import multiprocessing\n",
    "\n",
    "#inicia relogio\n",
    "t1 = time.time()\n",
    "# Define o tamanho das divisões feitas no dataset (cross-validation)\n",
    "n_dobras = 10\n",
    "# Define Tamanho inicial da amostra (toda estratégia parte de um tamanho mínimo).\n",
    "t_inicial = 10\n",
    "\n",
    "#define array de indices das partições\n",
    "idx_data =[]\n",
    "# cross validation bags - n_splits\n",
    "data_cv = StratifiedShuffleSplit(n_splits= n_dobras,train_size=99996,test_size=99996,random_state=42) \n",
    "data_cv.get_n_splits(X_raw, y_raw)\n",
    "# chame a instância e gere os dados sobre a base original\n",
    "type(data_cv.split(X_raw, y_raw))\n",
    "# dividir os dados - A função split.split () retorna índices para amostras de treino e amostras de teste. \n",
    "# Ele examinará o número de validação cruzada especificado e retornará cada vez que treinar \n",
    "# e testar os índices de amostra usando os conjuntos de dados de treinamento e teste que podem \n",
    "# ser criados filtrando o conjunto de dados inteiro. Por exemplo idx_data[0][1], o primeiro indice faz referencia\n",
    "# a dobra e o segundo indice faz referencia a posição da dobra (0 = treino e 1 = teste). Logo TRAIN=0 e TEST=1.\n",
    "for train_index, test_index in data_cv.split(X_raw,y_raw):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    #print(\"n_split\",n_splits,\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    idx_data.append([train_index, test_index])\n",
    "#verifica tamanho das dobras (numero de instâncias de cada dobra)\n",
    "#print(\"tamanho de cada dobra: \",idx_data[3][0].shape)\n",
    "\n",
    "TRAIN =0\n",
    "TEST =1\n",
    "\n",
    "# DEFINE NUMERO DE QUERIES\n",
    "BATCH_SIZE = 400\n",
    "N_RAW_SAMPLES = 20000\n",
    "N_QUERIES = N_RAW_SAMPLES // BATCH_SIZE\n",
    "\n",
    "#chama procedimento de aprendizado para todas as dobras\n",
    "\n",
    "for idx_dobra in range(n_dobras):    \n",
    "    #threading.Thread(target=random_sampling_knn(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    #threading.Thread(target=random_sampling_rf(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    #threading.Thread(target=random_sampling_nb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    #threading.Thread(target=random_sampling_mlp(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    #threading.Thread(target=random_sampling_tree(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    #threading.Thread(target=random_sampling_xgb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    #threading.Thread(target=random_sampling_svm(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    #threading.Thread(target=random_sampling_adb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    \n",
    "t2 = time.time()\n",
    "time_elapsed = (t2-t1)\n",
    "hours, rem = divmod(time_elapsed, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"Tempo Total: {:0>2}:{:0>2}:{:0>2}\".format(int(hours),int(minutes),int(seconds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
