{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from numpy import array, savetxt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega o dataset\n",
    "dados = pd.read_csv('/home/erasmor/Downloads/2017/todos_apenas_baixa_representatividade.csv',sep=\",\",encoding = 'utf-8',  header=0,na_values='.',dtype={'Label':'category'})\n",
    "\n",
    "#remove valores infinitos\n",
    "dados.replace(-np.Inf, np.nan)\n",
    "\n",
    "#substitui valores NaN\n",
    "dados.fillna(dados.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica quantas instâncias (linhas) e quantos atributos (colunas) a base de dados contém\n",
    "print(\"numero de linhas e colunas: \",dados.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar distribições por classes contidas no csv - informar nome da classe alvo\n",
    "print(dados.groupby('Label').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_raw_normalize = MinMaxScaler(X_raw_normalize.reshape(0, 1)).reshape(len(X_raw_normalize))\n",
    "#X_raw_normalizetd2 = (X_raw_normalize - X_raw_normalize.min(axis=0)) / (X_raw_normalize.max(axis=0) - X_raw_normalize.min(axis=0))\n",
    "# Obtendo os nomes das colunas do DataFrame como uma lista.\n",
    "cols = list(dados.columns)\n",
    "# colunas que nao serao normalizadas\n",
    "cols.remove('Label')\n",
    "\n",
    "# Copiando os dados e aplicando a normalizacao por reescala nas colunas do DataFrame que contem\n",
    "# valores continuos. Por padrao, o metodo minmax_scale reescala com min=0 e max=1.\n",
    "dados = dados[~dados.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "dados[cols] = dados[cols].apply(minmax_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define as colunas de atributos e a coluna da classe (de 0 a 72 são atributos e após a 72 é a classe)\n",
    "# \"X_raw\" é features/atributos e \"y_raw\" é target/classe ==> As duas formas abaixo dão certo.\n",
    "#array = dataset.values\n",
    "#X_raw = array[:,0:72]\n",
    "#y_raw = array[:,72]\n",
    "X_raw = dados.iloc[:, :-1].values # atributos\n",
    "y_raw = dados.iloc[:, 78].values # classe de ataques\n",
    "X_raw = np.nan_to_num(X_raw.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformar a variável Y com valores categóricos das classses de ataques em valores:\n",
    "labelencoder_y = LabelEncoder()\n",
    "y_raw = labelencoder_y.fit_transform(y_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando um PCA. O parametro n_components indica a quantidade de dimensoes que a base\n",
    "# original sera reduzida.\n",
    "pca = PCA(n_components=10, whiten=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o pca na base de dados. O atributo 'values' retorna um numpy.array\n",
    "# de duas dimensões (matriz) contendo apenas os valores numericos do DataFrame.\n",
    "X_raw = pca.fit_transform(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Expected_Model_Change_function_knn(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #indica index da dobra para uso nos arquivos\n",
    "    indica_pool=str(idx_dobra)\n",
    "    \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    #print(\"tamanho de X_train inicial: \",X_train_inicial.shape,\" tamanho de y_train inicial: \",y_train_inicial.shape)\n",
    "    #print(y_train_inicial)  \n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "    \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_knn = ActiveLearner(estimator=KNeighborsClassifier(n_neighbors=5),X_training=X_train, y_training=y_train)\n",
    "    arquivo_accuracy_knn = open(\"model_accuracy_performance_knn_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_knn = (\"model_accuracy_history_knn_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_knn = (\"model_F1_Score_history_knn_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_knn = (\"model_tempo_history_knn_dobra_\"+indica_pool+\".csv\")\n",
    "        \n",
    "    #verifica a performance inicial\n",
    "    performance_history_knn=[]\n",
    "    f1_score_history_knn=[]\n",
    "    tempo_history_knn=[]\n",
    "    unqueried_score_knn = learner_knn.score(X_teste, y_teste)\n",
    "    predictions = learner_knn.predict(X_teste)\n",
    "    performance_history_knn.append(unqueried_score_knn)\n",
    "    f1score_knn = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_knn.append(f1score_knn)\n",
    "    \n",
    "    #inicio aprendizado ativo\n",
    " \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_knn = time.time()\n",
    "        n_labeled_examples_news = X_pool.shape[0]\n",
    "        training_indices_news = np.random.randint(low=0, high=n_labeled_examples_news, size=BATCH_SIZE)\n",
    "        amostra_recuperada_X = X_pool[training_indices_news]\n",
    "        amostra_recuperada_y = y_pool[training_indices_news]\n",
    "        temp_knn = deepcopy(learner_knn)\n",
    "        temp_knn.teach(amostra_recuperada_X, amostra_recuperada_y)\n",
    "        score_temp_knn = temp_knn.score(X_teste, y_teste)\n",
    "        score_learner_knn = learner_knn.score(X_teste, y_teste)\n",
    "        if score_temp_knn > score_learner_knn:\n",
    "            learner_knn.teach(X=amostra_recuperada_X,y=amostra_recuperada_y)\n",
    "            clear_output(wait=True)\n",
    "            predictions = learner_knn.predict(X_teste)\n",
    "            performance_history_knn.append(accuracy_score(y_teste, predictions))\n",
    "            print ('Accuracy KNN after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "            arquivo_accuracy_knn.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "            #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_knn.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_knn.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #arquivo_accuracy_knn.write('F1 score after query no. %d: %f \\n' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            f1score_knn= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            f1_score_history_knn.append(f1score_knn)\n",
    "            arquivo_accuracy_knn.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_knn))\n",
    "            #print (\"========================================\")\n",
    "            arquivo_accuracy_knn.write('======================================== \\n')\n",
    "        \n",
    "        X_pool = np.delete(X_pool, training_indices_news, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_news, axis=0)\n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_knn = time.time()\n",
    "        time_elapsed_knn = (t2_knn-t1_knn)\n",
    "        hours_knn, rem_knn = divmod(time_elapsed_knn, 3600)\n",
    "        minutes_knn, seconds_knn = divmod(rem_knn, 60)\n",
    "        tempo_history_knn.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_knn),int(minutes_knn),int(seconds_knn)))\n",
    "        \n",
    "                                \n",
    "    arquivo_accuracy_knn.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_knn.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_knn, performance_history_knn,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_knn, f1_score_history_knn)\n",
    "    np.savetxt(arquivo_tempo_history_knn,tempo_history_knn,fmt=\"%s\")\n",
    "    arquivo_accuracy_knn.close()\n",
    "\n",
    "def Expected_Model_Change_function_rf(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #indica index da dobra para uso nos arquivos\n",
    "    indica_pool=str(idx_dobra)\n",
    "    \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    #print(\"tamanho de X_train inicial: \",X_train_inicial.shape,\" tamanho de y_train inicial: \",y_train_inicial.shape)\n",
    "    #print(y_train_inicial)  \n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "    \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_rf = ActiveLearner(estimator=RandomForestClassifier(random_state=42),X_training=X_train, y_training=y_train)\n",
    "    arquivo_accuracy_rf = open(\"model_accuracy_performance_rf_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_rf = (\"model_accuracy_history_rf_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_rf = (\"model_F1_Score_history_rf_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_rf = (\"model_tempo_history_rf_dobra_\"+indica_pool+\".csv\")\n",
    "        \n",
    "    #verifica a performance inicial\n",
    "    performance_history_rf=[]\n",
    "    f1_score_history_rf=[]\n",
    "    tempo_history_rf=[]\n",
    "    unqueried_score_rf = learner_rf.score(X_teste, y_teste)\n",
    "    predictions = learner_rf.predict(X_teste)\n",
    "    performance_history_rf.append(unqueried_score_rf)\n",
    "    f1score_rf = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_rf.append(f1score_rf)\n",
    "    \n",
    "    #inicio aprendizado ativo\n",
    " \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_rf = time.time()\n",
    "        n_labeled_examples_news = X_pool.shape[0]\n",
    "        training_indices_news = np.random.randint(low=0, high=n_labeled_examples_news, size=BATCH_SIZE)\n",
    "        amostra_recuperada_X = X_pool[training_indices_news]\n",
    "        amostra_recuperada_y = y_pool[training_indices_news]\n",
    "        temp_rf = deepcopy(learner_rf)\n",
    "        temp_rf.teach(amostra_recuperada_X, amostra_recuperada_y)\n",
    "        score_temp_rf = temp_rf.score(X_teste, y_teste)\n",
    "        score_learner_rf = learner_rf.score(X_teste, y_teste)\n",
    "        if score_temp_rf > score_learner_rf:\n",
    "            learner_rf.teach(X=amostra_recuperada_X,y=amostra_recuperada_y)\n",
    "            clear_output(wait=True)\n",
    "            predictions = learner_rf.predict(X_teste)\n",
    "            performance_history_rf.append(accuracy_score(y_teste, predictions))\n",
    "            print ('Accuracy_rf after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "            arquivo_accuracy_rf.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "            #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_rf.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_rf.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #arquivo_accuracy_rf.write('F1 score after query no. %d: %f \\n' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            f1score_rf= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            f1_score_history_rf.append(f1score_rf)\n",
    "            arquivo_accuracy_rf.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_rf))\n",
    "            #print (\"========================================\")\n",
    "            arquivo_accuracy_rf.write('======================================== \\n')\n",
    "        \n",
    "        X_pool = np.delete(X_pool, training_indices_news, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_news, axis=0)\n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_rf = time.time()\n",
    "        time_elapsed_rf = (t2_rf-t1_rf)\n",
    "        hours_rf, rem_rf = divmod(time_elapsed_rf, 3600)\n",
    "        minutes_rf, seconds_rf = divmod(rem_rf, 60)\n",
    "        tempo_history_rf.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_rf),int(minutes_rf),int(seconds_rf)))\n",
    "        \n",
    "                                \n",
    "    arquivo_accuracy_rf.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_rf.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_rf, performance_history_rf,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_rf, f1_score_history_rf)\n",
    "    np.savetxt(arquivo_tempo_history_rf,tempo_history_rf,fmt=\"%s\")\n",
    "    arquivo_accuracy_rf.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "def Expected_Model_Change_function_tree(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #indica index da dobra para uso nos arquivos\n",
    "    indica_pool=str(idx_dobra)\n",
    "    \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    #print(\"tamanho de X_train inicial: \",X_train_inicial.shape,\" tamanho de y_train inicial: \",y_train_inicial.shape)\n",
    "    #print(y_train_inicial)  \n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "    \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_tree = ActiveLearner(estimator=DecisionTreeClassifier(),X_training=X_train, y_training=y_train)\n",
    "    arquivo_accuracy_tree = open(\"model_accuracy_performance_tree_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_tree = (\"model_accuracy_history_tree_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_tree = (\"model_F1_Score_history_tree_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_tree = (\"model_tempo_history_tree_dobra_\"+indica_pool+\".csv\")\n",
    "        \n",
    "    #verifica a performance inicial\n",
    "    performance_history_tree=[]\n",
    "    f1_score_history_tree=[]\n",
    "    tempo_history_tree=[]\n",
    "    unqueried_score_tree = learner_tree.score(X_teste, y_teste)\n",
    "    predictions = learner_tree.predict(X_teste)\n",
    "    performance_history_tree.append(unqueried_score_tree)\n",
    "    f1score_tree = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_tree.append(f1score_tree)\n",
    "    \n",
    "    #inicio aprendizado ativo\n",
    " \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_tree = time.time()\n",
    "        n_labeled_examples_news = X_pool.shape[0]\n",
    "        training_indices_news = np.random.randint(low=0, high=n_labeled_examples_news, size=BATCH_SIZE)\n",
    "        amostra_recuperada_X = X_pool[training_indices_news]\n",
    "        amostra_recuperada_y = y_pool[training_indices_news]\n",
    "        temp_tree = deepcopy(learner_tree)\n",
    "        temp_tree.teach(amostra_recuperada_X, amostra_recuperada_y)\n",
    "        score_temp_tree = temp_tree.score(X_teste, y_teste)\n",
    "        score_learner_tree = learner_tree.score(X_teste, y_teste)\n",
    "        if score_temp_tree > score_learner_tree:\n",
    "            learner_tree.teach(X=amostra_recuperada_X,y=amostra_recuperada_y)\n",
    "            clear_output(wait=True)\n",
    "            predictions = learner_tree.predict(X_teste)\n",
    "            performance_history_tree.append(accuracy_score(y_teste, predictions))\n",
    "            print ('Accuracy_tree after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "            arquivo_accuracy_tree.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "            #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_tree.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_tree.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #arquivo_accuracy_tree.write('F1 score after query no. %d: %f \\n' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            f1score_tree= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            f1_score_history_tree.append(f1score_tree)\n",
    "            arquivo_accuracy_tree.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_tree))\n",
    "            #print (\"========================================\")\n",
    "            arquivo_accuracy_tree.write('======================================== \\n')\n",
    "        \n",
    "        X_pool = np.delete(X_pool, training_indices_news, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_news, axis=0)\n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_tree = time.time()\n",
    "        time_elapsed_tree = (t2_tree-t1_tree)\n",
    "        hours_tree, rem_tree = divmod(time_elapsed_tree, 3600)\n",
    "        minutes_tree, seconds_tree = divmod(rem_tree, 60)\n",
    "        tempo_history_tree.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_tree),int(minutes_tree),int(seconds_tree)))\n",
    "        \n",
    "                                \n",
    "    arquivo_accuracy_tree.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_tree.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_tree, performance_history_tree,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_tree, f1_score_history_tree)\n",
    "    np.savetxt(arquivo_tempo_history_tree,tempo_history_tree,fmt=\"%s\")\n",
    "    arquivo_accuracy_tree.close()\n",
    "\n",
    "def Expected_Model_Change_function_mlp(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #indica index da dobra para uso nos arquivos\n",
    "    indica_pool=str(idx_dobra)\n",
    "    \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    #print(\"tamanho de X_train inicial: \",X_train_inicial.shape,\" tamanho de y_train inicial: \",y_train_inicial.shape)\n",
    "    #print(y_train_inicial)  \n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "    \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_mlp = ActiveLearner(estimator=MLPClassifier(max_iter = 2000),X_training=X_train, y_training=y_train)\n",
    "    arquivo_accuracy_mlp = open(\"model_accuracy_performance_mlp_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_mlp = (\"model_accuracy_history_mlp_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_mlp = (\"model_F1_Score_history_mlp_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_mlp = (\"model_tempo_history_mlp_dobra_\"+indica_pool+\".csv\")\n",
    "        \n",
    "    #verifica a performance inicial\n",
    "    performance_history_mlp=[]\n",
    "    f1_score_history_mlp=[]\n",
    "    tempo_history_mlp=[]\n",
    "    unqueried_score_mlp = learner_mlp.score(X_teste, y_teste)\n",
    "    predictions = learner_mlp.predict(X_teste)\n",
    "    performance_history_mlp.append(unqueried_score_mlp)\n",
    "    f1score_mlp = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_mlp.append(f1score_mlp)\n",
    "    \n",
    "    #inicio aprendizado ativo\n",
    " \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_mlp = time.time()\n",
    "        n_labeled_examples_news = X_pool.shape[0]\n",
    "        training_indices_news = np.random.randint(low=0, high=n_labeled_examples_news, size=BATCH_SIZE)\n",
    "        amostra_recuperada_X = X_pool[training_indices_news]\n",
    "        amostra_recuperada_y = y_pool[training_indices_news]\n",
    "        temp_mlp = deepcopy(learner_mlp)\n",
    "        temp_mlp.teach(amostra_recuperada_X, amostra_recuperada_y)\n",
    "        score_temp_mlp = temp_mlp.score(X_teste, y_teste)\n",
    "        score_learner_mlp = learner_mlp.score(X_teste, y_teste)\n",
    "        if score_temp_mlp > score_learner_mlp:\n",
    "            learner_mlp.teach(X=amostra_recuperada_X,y=amostra_recuperada_y)\n",
    "            clear_output(wait=True)\n",
    "            predictions = learner_mlp.predict(X_teste)\n",
    "            performance_history_mlp.append(accuracy_score(y_teste, predictions))\n",
    "            print ('Accuracy_mlp after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "            arquivo_accuracy_mlp.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "            #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_mlp.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_mlp.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #arquivo_accuracy_mlp.write('F1 score after query no. %d: %f \\n' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            f1score_mlp= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            f1_score_history_mlp.append(f1score_mlp)\n",
    "            arquivo_accuracy_mlp.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_mlp))\n",
    "            #print (\"========================================\")\n",
    "            arquivo_accuracy_mlp.write('======================================== \\n')\n",
    "        \n",
    "        X_pool = np.delete(X_pool, training_indices_news, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_news, axis=0)\n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_mlp = time.time()\n",
    "        time_elapsed_mlp = (t2_mlp-t1_mlp)\n",
    "        hours_mlp, rem_mlp = divmod(time_elapsed_mlp, 3600)\n",
    "        minutes_mlp, seconds_mlp = divmod(rem_mlp, 60)\n",
    "        tempo_history_mlp.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_mlp),int(minutes_mlp),int(seconds_mlp)))\n",
    "        \n",
    "                                \n",
    "    arquivo_accuracy_mlp.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_mlp.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_mlp, performance_history_mlp,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_mlp, f1_score_history_mlp)\n",
    "    np.savetxt(arquivo_tempo_history_mlp,tempo_history_mlp,fmt=\"%s\")\n",
    "    arquivo_accuracy_mlp.close()\n",
    "\n",
    "                                  \n",
    "def Expected_Model_Change_function_xgb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #indica index da dobra para uso nos arquivos\n",
    "    indica_pool=str(idx_dobra)\n",
    "    \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    #print(\"tamanho de X_train inicial: \",X_train_inicial.shape,\" tamanho de y_train inicial: \",y_train_inicial.shape)\n",
    "    #print(y_train_inicial)  \n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "    \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_xgb = ActiveLearner(estimator=GradientBoostingClassifier(n_estimators=7, learning_rate=1.0,max_depth=1, random_state=42),X_training=X_train, y_training=y_train)\n",
    "    arquivo_accuracy_xgb = open(\"model_accuracy_performance_xgb_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_xgb = (\"model_accuracy_history_xgb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_xgb = (\"model_F1_Score_history_xgb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_xgb = (\"model_tempo_history_xgb_dobra_\"+indica_pool+\".csv\")\n",
    "        \n",
    "    #verifica a performance inicial\n",
    "    performance_history_xgb=[]\n",
    "    f1_score_history_xgb=[]\n",
    "    tempo_history_xgb=[]\n",
    "    unqueried_score_xgb = learner_xgb.score(X_teste, y_teste)\n",
    "    predictions = learner_xgb.predict(X_teste)\n",
    "    performance_history_xgb.append(unqueried_score_xgb)\n",
    "    f1score_xgb = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_xgb.append(f1score_xgb)\n",
    "    \n",
    "    #inicio aprendizado ativo\n",
    " \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_xgb = time.time()\n",
    "        n_labeled_examples_news = X_pool.shape[0]\n",
    "        training_indices_news = np.random.randint(low=0, high=n_labeled_examples_news, size=BATCH_SIZE)\n",
    "        amostra_recuperada_X = X_pool[training_indices_news]\n",
    "        amostra_recuperada_y = y_pool[training_indices_news]\n",
    "        temp_xgb = deepcopy(learner_xgb)\n",
    "        temp_xgb.teach(amostra_recuperada_X, amostra_recuperada_y)\n",
    "        score_temp_xgb = temp_xgb.score(X_teste, y_teste)\n",
    "        score_learner_xgb = learner_xgb.score(X_teste, y_teste)\n",
    "        if score_temp_xgb > score_learner_xgb:\n",
    "            learner_xgb.teach(X=amostra_recuperada_X,y=amostra_recuperada_y)\n",
    "            clear_output(wait=True)\n",
    "            predictions = learner_xgb.predict(X_teste)\n",
    "            performance_history_xgb.append(accuracy_score(y_teste, predictions))\n",
    "            print ('Accuracy_xgb after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "            arquivo_accuracy_xgb.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "            #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_xgb.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_xgb.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #arquivo_accuracy_xgb.write('F1 score after query no. %d: %f \\n' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            f1score_xgb= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            f1_score_history_xgb.append(f1score_xgb)\n",
    "            arquivo_accuracy_xgb.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_xgb))\n",
    "            #print (\"========================================\")\n",
    "            arquivo_accuracy_xgb.write('======================================== \\n')\n",
    "        \n",
    "        X_pool = np.delete(X_pool, training_indices_news, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_news, axis=0)\n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_xgb = time.time()\n",
    "        time_elapsed_xgb = (t2_xgb-t1_xgb)\n",
    "        hours_xgb, rem_xgb = divmod(time_elapsed_xgb, 3600)\n",
    "        minutes_xgb, seconds_xgb = divmod(rem_xgb, 60)\n",
    "        tempo_history_xgb.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_xgb),int(minutes_xgb),int(seconds_xgb)))\n",
    "        \n",
    "                                \n",
    "    arquivo_accuracy_xgb.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_xgb.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_xgb, performance_history_xgb,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_xgb, f1_score_history_xgb)\n",
    "    np.savetxt(arquivo_tempo_history_xgb,tempo_history_xgb,fmt=\"%s\")\n",
    "    arquivo_accuracy_xgb.close()\n",
    "                                 \n",
    "    \n",
    "    \n",
    "\n",
    "def Expected_Model_Change_function_svm(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn import svm\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #indica index da dobra para uso nos arquivos\n",
    "    indica_pool=str(idx_dobra)\n",
    "    \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    #print(\"tamanho de X_train inicial: \",X_train_inicial.shape,\" tamanho de y_train inicial: \",y_train_inicial.shape)\n",
    "    #print(y_train_inicial)  \n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "    \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_svm = ActiveLearner(estimator=svm.SVC(kernel='linear',probability=True),X_training=X_train, y_training=y_train)\n",
    "    arquivo_accuracy_svm = open(\"model_accuracy_performance_svm_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_svm = (\"model_accuracy_history_svm_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_svm = (\"model_F1_Score_history_svm_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_svm = (\"model_tempo_history_svm_dobra_\"+indica_pool+\".csv\")\n",
    "        \n",
    "    #verifica a performance inicial\n",
    "    performance_history_svm=[]\n",
    "    f1_score_history_svm=[]\n",
    "    tempo_history_svm=[]\n",
    "    unqueried_score_svm = learner_svm.score(X_teste, y_teste)\n",
    "    predictions = learner_svm.predict(X_teste)\n",
    "    performance_history_svm.append(unqueried_score_svm)\n",
    "    f1score_svm = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_svm.append(f1score_svm)\n",
    "    \n",
    "    #inicio aprendizado ativo\n",
    " \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_svm = time.time()\n",
    "        n_labeled_examples_news = X_pool.shape[0]\n",
    "        training_indices_news = np.random.randint(low=0, high=n_labeled_examples_news, size=BATCH_SIZE)\n",
    "        amostra_recuperada_X = X_pool[training_indices_news]\n",
    "        amostra_recuperada_y = y_pool[training_indices_news]\n",
    "        temp_svm = deepcopy(learner_svm)\n",
    "        temp_svm.teach(amostra_recuperada_X, amostra_recuperada_y)\n",
    "        score_temp_svm = temp_svm.score(X_teste, y_teste)\n",
    "        score_learner_svm = learner_svm.score(X_teste, y_teste)\n",
    "        if score_temp_svm > score_learner_svm:\n",
    "            learner_svm.teach(X=amostra_recuperada_X,y=amostra_recuperada_y)\n",
    "            clear_output(wait=True)\n",
    "            predictions = learner_svm.predict(X_teste)\n",
    "            performance_history_svm.append(accuracy_score(y_teste, predictions))\n",
    "            print ('Accuracy_svm after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "            arquivo_accuracy_svm.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "            #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_svm.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_svm.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #arquivo_accuracy_svm.write('F1 score after query no. %d: %f \\n' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            f1score_svm= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            f1_score_history_svm.append(f1score_svm)\n",
    "            arquivo_accuracy_svm.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_svm))\n",
    "            #print (\"========================================\")\n",
    "            arquivo_accuracy_svm.write('======================================== \\n')\n",
    "        \n",
    "        X_pool = np.delete(X_pool, training_indices_news, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_news, axis=0)\n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_svm = time.time()\n",
    "        time_elapsed_svm = (t2_svm-t1_svm)\n",
    "        hours_svm, rem_svm = divmod(time_elapsed_svm, 3600)\n",
    "        minutes_svm, seconds_svm = divmod(rem_svm, 60)\n",
    "        tempo_history_svm.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_svm),int(minutes_svm),int(seconds_svm)))\n",
    "        \n",
    "                                \n",
    "    arquivo_accuracy_svm.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_svm.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_svm, performance_history_svm,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_svm, f1_score_history_svm)\n",
    "    np.savetxt(arquivo_tempo_history_svm,tempo_history_svm,fmt=\"%s\")\n",
    "    arquivo_accuracy_svm.close()\n",
    "\n",
    "def Expected_Model_Change_function_nb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "    import functools\n",
    "    from IPython.display import clear_output\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #indica index da dobra para uso nos arquivos\n",
    "    indica_pool=str(idx_dobra)\n",
    "    \n",
    "    # recupera as amostras de treino iniciais - a extratificação realizada só serve para tal finalidade.\n",
    "    # No caso força a buscar pelo menos uma amostras de cada rótulo disponível (train_size= len(np.unique(y_raw)).\n",
    "    # Realizar a busca aleatoriamente não garante iniciar com uma instância de cada classe.\n",
    "    X_train_inicial, X_test_inicial, y_train_inicial, y_test_inicial = train_test_split(X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]], train_size= len(np.unique(y_raw[idx_data[idx_dobra][TRAIN]])) + t_inicial, stratify = y_raw[idx_data[idx_dobra][TRAIN]])\n",
    "    #print(\"tamanho de X_train inicial: \",X_train_inicial.shape,\" tamanho de y_train inicial: \",y_train_inicial.shape)\n",
    "    #print(y_train_inicial)  \n",
    "    # recupera amostras de teste de acordo com a dobra em uso\n",
    "    X_teste, y_teste = X_raw[idx_data[idx_dobra][TEST]], y_raw[idx_data[idx_dobra][TEST]]\n",
    "    # recupera amostras de treino (será o pool) de acordo com a dobra em uso\n",
    "    X_pool, y_pool = X_raw[idx_data[idx_dobra][TRAIN]], y_raw[idx_data[idx_dobra][TRAIN]]\n",
    "    \n",
    "    #isola exemplos rotulados para o treinamento inicial\n",
    "    X_train = X_train_inicial\n",
    "    y_train = y_train_inicial\n",
    "    \n",
    "    #instanciando classificadores de aprendizado ativo\n",
    "    learner_nb = ActiveLearner(estimator=GaussianNB(),X_training=X_train, y_training=y_train)\n",
    "    arquivo_accuracy_nb = open(\"model_accuracy_performance_nb_dobra_\"+indica_pool+\".txt\",\"a\")\n",
    "    arquivo_accuracy_history_nb = (\"model_accuracy_history_nb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_f1_score_history_nb = (\"model_F1_Score_history_nb_dobra_\"+indica_pool+\".csv\")\n",
    "    arquivo_tempo_history_nb = (\"model_tempo_history_nb_dobra_\"+indica_pool+\".csv\")\n",
    "        \n",
    "    #verifica a performance inicial\n",
    "    performance_history_nb=[]\n",
    "    f1_score_history_nb=[]\n",
    "    tempo_history_nb=[]\n",
    "    unqueried_score_nb = learner_nb.score(X_teste, y_teste)\n",
    "    predictions = learner_nb.predict(X_teste)\n",
    "    performance_history_nb.append(unqueried_score_nb)\n",
    "    f1score_nb = 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "    f1_score_history_nb.append(f1score_nb)\n",
    "    \n",
    "    #inicio aprendizado ativo\n",
    " \n",
    "    for index in range(N_QUERIES):\n",
    "        #inicia calculo do tempo de processamento da estratégia (consulta e inserção)\n",
    "        t1_nb = time.time()\n",
    "        n_labeled_examples_news = X_pool.shape[0]\n",
    "        training_indices_news = np.random.randint(low=0, high=n_labeled_examples_news, size=BATCH_SIZE)\n",
    "        amostra_recuperada_X = X_pool[training_indices_news]\n",
    "        amostra_recuperada_y = y_pool[training_indices_news]\n",
    "        temp_nb = deepcopy(learner_nb)\n",
    "        temp_nb.teach(amostra_recuperada_X, amostra_recuperada_y)\n",
    "        score_temp_nb = temp_nb.score(X_teste, y_teste)\n",
    "        score_learner_nb = learner_nb.score(X_teste, y_teste)\n",
    "        if score_temp_nb > score_learner_nb:\n",
    "            learner_nb.teach(X=amostra_recuperada_X,y=amostra_recuperada_y)\n",
    "            clear_output(wait=True)\n",
    "            predictions = learner_nb.predict(X_teste)\n",
    "            performance_history_nb.append(accuracy_score(y_teste, predictions))\n",
    "            print ('Accuracy_nb after query no. %d: %f' % (index+1, accuracy_score(y_teste, predictions)))\n",
    "            arquivo_accuracy_nb.write('Accuracy after query no. %d: %f \\n' % (index+1,accuracy_score(y_teste, predictions)))\n",
    "            #print ('Precision after query no. %d: %f' % (index+1, precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_nb.write('Precision after query no. %d: %f \\n' % (index+1,precision_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #print ('Recall after query no. %d: %f' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            arquivo_accuracy_nb.write('Recall after query no. %d: %f \\n' % (index+1, recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            #print ('F1 score after query no. %d: %f' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            #arquivo_accuracy_nb.write('F1 score after query no. %d: %f \\n' % (index+1, f1_score(y_teste, predictions,average='macro',zero_division=1)))\n",
    "            f1score_nb= 2*((precision_score(y_teste, predictions,average='macro',zero_division=1)*recall_score(y_teste, predictions, average='macro',zero_division=1))/(precision_score(y_teste, predictions,average='macro',zero_division=1)+recall_score(y_teste, predictions, average='macro',zero_division=1)))\n",
    "            f1_score_history_nb.append(f1score_nb)\n",
    "            arquivo_accuracy_nb.write('F1 score after query no. %d: %f \\n' % (index+1, f1score_nb))\n",
    "            #print (\"========================================\")\n",
    "            arquivo_accuracy_nb.write('======================================== \\n')\n",
    "        \n",
    "        X_pool = np.delete(X_pool, training_indices_news, axis=0)\n",
    "        y_pool = np.delete(y_pool, training_indices_news, axis=0)\n",
    "        #termina calculo de processamentoda estratégia\n",
    "        t2_nb = time.time()\n",
    "        time_elapsed_nb = (t2_nb-t1_nb)\n",
    "        hours_nb, rem_nb = divmod(time_elapsed_nb, 3600)\n",
    "        minutes_nb, seconds_nb = divmod(rem_nb, 60)\n",
    "        tempo_history_nb.append(\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours_nb),int(minutes_nb),int(seconds_nb)))\n",
    "        \n",
    "                                \n",
    "    arquivo_accuracy_nb.write(\"\\n Avaliação por classe \\n\")\n",
    "    arquivo_accuracy_nb.write(classification_report(y_teste, predictions,zero_division=1))  \n",
    "    np.savetxt(arquivo_accuracy_history_nb, performance_history_nb,delimiter=\",\")\n",
    "    np.savetxt(arquivo_f1_score_history_nb, f1_score_history_nb)\n",
    "    np.savetxt(arquivo_tempo_history_nb,tempo_history_nb,fmt=\"%s\")\n",
    "    arquivo_accuracy_nb.close()\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit, train_test_split\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "from functools import partial\n",
    "from timeit import Timer\n",
    "import time\n",
    "import functools\n",
    "# importing the multiprocessing module\n",
    "import multiprocessing\n",
    "\n",
    "#inicia relogio\n",
    "t1 = time.time()\n",
    "# Define o tamanho das divisões feitas no dataset (cross-validation)\n",
    "n_dobras = 10\n",
    "# Define Tamanho inicial da amostra (toda estratégia parte de um tamanho mínimo aleatório).\n",
    "t_inicial = 10\n",
    "#define array de indices das partições\n",
    "idx_data =[]\n",
    "# cross validation bags - n_splits\n",
    "data_cv = StratifiedShuffleSplit(n_splits= n_dobras,train_size=346,test_size=346,random_state=42) \n",
    "data_cv.get_n_splits(X_raw, y_raw)\n",
    "# chame a instância e gere os dados sobre a base original\n",
    "type(data_cv.split(X_raw, y_raw))\n",
    "# dividir os dados - A função split.split () retorna índices para amostras de treino e amostras de teste. \n",
    "# Ele examinará o número de validação cruzada especificado e retornará cada vez que treinar \n",
    "# e testar os índices de amostra usando os conjuntos de dados de treinamento e teste que podem \n",
    "# ser criados filtrando o conjunto de dados inteiro. Por exemplo idx_data[0][1], o primeiro indice faz referencia\n",
    "# a dobra e o segundo indice faz referencia a posição da dobra (0 = treino e 1 = teste). Logo TRAIN=0 e TEST=1.\n",
    "for train_index, test_index in data_cv.split(X_raw,y_raw):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    #print(\"n_split\",n_splits,\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    idx_data.append([train_index, test_index])\n",
    "#verifica tamanho das dobras (numero de instâncias de cada dobra)\n",
    "#print(\"tamanho de cada dobra: \",idx_data[3][0].shape)\n",
    "\n",
    "\n",
    "TRAIN =0\n",
    "TEST =1\n",
    "\n",
    "# Define numero de queries\n",
    "BATCH_SIZE = 4\n",
    "N_RAW_SAMPLES = 32\n",
    "N_QUERIES = N_RAW_SAMPLES // BATCH_SIZE\n",
    "#chama procedimento de aprendizado para todas as dobras\n",
    "for idx_dobra in range(1):\n",
    "    threading.Thread(target=Expected_Model_Change_function_knn(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    threading.Thread(target=Expected_Model_Change_function_rf(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    threading.Thread(target=Expected_Model_Change_function_nb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    threading.Thread(target=Expected_Model_Change_function_mlp(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    threading.Thread(target=Expected_Model_Change_function_tree(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    #threading.Thread(target=Expected_Model_Change_function_xgb(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "    #threading.Thread(target=Expected_Model_Change_function_svm(X_raw, y_raw, idx_data, idx_dobra, TRAIN, TEST, t_inicial)).start()\n",
    "\n",
    "       \n",
    "t2 = time.time()\n",
    "time_elapsed = (t2-t1)\n",
    "hours, rem = divmod(time_elapsed, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"Tempo total: {:0>2}:{:0>2}:{:0>2}\".format(int(hours),int(minutes),int(seconds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
